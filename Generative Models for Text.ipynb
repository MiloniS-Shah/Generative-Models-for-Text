{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)In this problem, we are trying to build a generative model to mimic the writing style of prominent British Mathematician, Philosopher, prolific writer, and political activist, Bertrand Russell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Download the following books from Project Gutenberg http://www.gutenberg.org/ebooks/author/355 in text format: <br>\n",
    "i. The Problems of Philosophy<br>\n",
    "ii. The Analysis of Mind<br>\n",
    "iii. Mysticism and Logic and Other Essays<br>\n",
    "iv. Our Knowledge of the External World as a Field for Scientific Method in Philosophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"book1.txt\"\n",
    "raw_text=open(filename,encoding='utf-8').read()\n",
    "raw_text=raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)ii.Use a character-level representation for this model by using extended ASCII that has N = 256 characters. Each character will be encoded into a an integer using its ASCII code. Rescale the integers to the range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=sorted(list(set(raw_text)))\n",
    "char_to_int=dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '&': 4, \"'\": 5, '(': 6, ')': 7, '*': 8, '+': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '=': 26, '>': 27, '?': 28, '[': 29, ']': 30, '_': 31, 'a': 32, 'b': 33, 'c': 34, 'd': 35, 'e': 36, 'f': 37, 'g': 38, 'h': 39, 'i': 40, 'j': 41, 'k': 42, 'l': 43, 'm': 44, 'n': 45, 'o': 46, 'p': 47, 'q': 48, 'r': 49, 's': 50, 't': 51, 'u': 52, 'v': 53, 'w': 54, 'x': 55, 'y': 56, 'z': 57, '{': 58, '|': 59, '}': 60, '\\xa0': 61, '§': 62, '·': 63, 'â': 64, 'æ': 65, 'è': 66, 'é': 67, 'ë': 68, 'î': 69, 'ï': 70, 'ô': 71, 'ö': 72, 'ü': 73, 'œ': 74, 'ŭ': 75, 'α': 76, 'β': 77, 'γ': 78, 'η': 79, 'θ': 80, 'ι': 81, 'κ': 82, 'λ': 83, 'ν': 84, 'ο': 85, 'π': 86, 'ρ': 87, 'σ': 88, 'τ': 89, 'φ': 90, 'ὴ': 91, 'ή': 92, 'ί': 93, 'ὸ': 94, 'ό': 95, '′': 96, '″': 97, '\\ufeff': 98}\n"
     ]
    }
   ],
   "source": [
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1577211\n",
      "Total Vocab:  99\n"
     ]
    }
   ],
   "source": [
    "n_chars=len(raw_text)\n",
    "n_vocab=len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)iii. iv. Choose a window size W = 100. <br> Inputs to the network will be the first W-1 = 99 characters of each sequence,and the output of the network will be the Wth character of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  1577111\n"
     ]
    }
   ],
   "source": [
    "window=100 #Window size=100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars-window, 1):\n",
    "\tseq_in = raw_text[i:i + window]\n",
    "\tseq_out = raw_text[i + window]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) v. Encode the output using one-hot encoding scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, window, 1))\n",
    "\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1577111, 98)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) vi.,vii.,viii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm=Sequential()\n",
    "lstm.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Dense(y.shape[1], activation='softmax'))\n",
    "lstm.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) ix. Choose a reasonable number of epochs for training, considering your computational power. \n",
    "## Using 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1577111/1577111 [==============================] - 4195s 3ms/step - loss: 2.7420\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.74202, saving model to weights-improvement-01-2.7420.hdf5\n",
      "Epoch 2/20\n",
      "1577111/1577111 [==============================] - 4244s 3ms/step - loss: 2.4698\n",
      "\n",
      "Epoch 00002: loss improved from 2.74202 to 2.46980, saving model to weights-improvement-02-2.4698.hdf5\n",
      "Epoch 3/20\n",
      "1577111/1577111 [==============================] - 4257s 3ms/step - loss: 2.2757\n",
      "\n",
      "Epoch 00003: loss improved from 2.46980 to 2.27567, saving model to weights-improvement-03-2.2757.hdf5\n",
      "Epoch 4/20\n",
      "1577111/1577111 [==============================] - 4207s 3ms/step - loss: 2.1552\n",
      "\n",
      "Epoch 00004: loss improved from 2.27567 to 2.15515, saving model to weights-improvement-04-2.1552.hdf5\n",
      "Epoch 5/20\n",
      "1577111/1577111 [==============================] - 4187s 3ms/step - loss: 2.0744\n",
      "\n",
      "Epoch 00005: loss improved from 2.15515 to 2.07437, saving model to weights-improvement-05-2.0744.hdf5\n",
      "Epoch 6/20\n",
      "1577111/1577111 [==============================] - 5491s 3ms/step - loss: 2.0177\n",
      "\n",
      "Epoch 00006: loss improved from 2.07437 to 2.01766, saving model to weights-improvement-06-2.0177.hdf5\n",
      "Epoch 7/20\n",
      "1577111/1577111 [==============================] - 23226s 15ms/step - loss: 1.9721\n",
      "\n",
      "Epoch 00007: loss improved from 2.01766 to 1.97210, saving model to weights-improvement-07-1.9721.hdf5\n",
      "Epoch 8/20\n",
      "1577111/1577111 [==============================] - 4132s 3ms/step - loss: 1.9364\n",
      "\n",
      "Epoch 00008: loss improved from 1.97210 to 1.93640, saving model to weights-improvement-08-1.9364.hdf5\n",
      "Epoch 9/20\n",
      "1577111/1577111 [==============================] - 4182s 3ms/step - loss: 1.9064\n",
      "\n",
      "Epoch 00009: loss improved from 1.93640 to 1.90640, saving model to weights-improvement-09-1.9064.hdf5\n",
      "Epoch 10/20\n",
      "1577111/1577111 [==============================] - 4138s 3ms/step - loss: 1.8808\n",
      "\n",
      "Epoch 00010: loss improved from 1.90640 to 1.88076, saving model to weights-improvement-10-1.8808.hdf5\n",
      "Epoch 11/20\n",
      "1577111/1577111 [==============================] - 4139s 3ms/step - loss: 1.8593\n",
      "\n",
      "Epoch 00011: loss improved from 1.88076 to 1.85930, saving model to weights-improvement-11-1.8593.hdf5\n",
      "Epoch 12/20\n",
      "1577111/1577111 [==============================] - 4136s 3ms/step - loss: 1.8398\n",
      "\n",
      "Epoch 00012: loss improved from 1.85930 to 1.83983, saving model to weights-improvement-12-1.8398.hdf5\n",
      "Epoch 13/20\n",
      "1577111/1577111 [==============================] - 4128s 3ms/step - loss: 1.8229\n",
      "\n",
      "Epoch 00013: loss improved from 1.83983 to 1.82286, saving model to weights-improvement-13-1.8229.hdf5\n",
      "Epoch 14/20\n",
      "1577111/1577111 [==============================] - 4085s 3ms/step - loss: 1.8085\n",
      "\n",
      "Epoch 00014: loss improved from 1.82286 to 1.80851, saving model to weights-improvement-14-1.8085.hdf5\n",
      "Epoch 15/20\n",
      "1577111/1577111 [==============================] - 4073s 3ms/step - loss: 1.7951\n",
      "\n",
      "Epoch 00015: loss improved from 1.80851 to 1.79510, saving model to weights-improvement-15-1.7951.hdf5\n",
      "Epoch 16/20\n",
      "1577111/1577111 [==============================] - 4851s 3ms/step - loss: 1.7830\n",
      "\n",
      "Epoch 00016: loss improved from 1.79510 to 1.78302, saving model to weights-improvement-16-1.7830.hdf5\n",
      "Epoch 17/20\n",
      "1577111/1577111 [==============================] - 4813s 3ms/step - loss: 1.7724\n",
      "\n",
      "Epoch 00017: loss improved from 1.78302 to 1.77243, saving model to weights-improvement-17-1.7724.hdf5\n",
      "Epoch 18/20\n",
      "1577111/1577111 [==============================] - 4124s 3ms/step - loss: 1.7626\n",
      "\n",
      "Epoch 00018: loss improved from 1.77243 to 1.76256, saving model to weights-improvement-18-1.7626.hdf5\n",
      "Epoch 19/20\n",
      "1577111/1577111 [==============================] - 4141s 3ms/step - loss: 1.7531\n",
      "\n",
      "Epoch 00019: loss improved from 1.76256 to 1.75305, saving model to weights-improvement-19-1.7531.hdf5\n",
      "Epoch 20/20\n",
      "1577111/1577111 [==============================] - 4092s 3ms/step - loss: 1.7438\n",
      "\n",
      "Epoch 00020: loss improved from 1.75305 to 1.74382, saving model to weights-improvement-20-1.7438.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215282b8b70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) x.Use model checkpointing to keep the network weights to determine each time an improvement in loss is observed at the end of the epoch. Find the best set of weights in terms of loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"weights-improvement-20-1.7438.hdf5\"\n",
    "lstm.load_weights(filename)\n",
    "lstm.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) xi.Use the network with the best weights to generate 1000 characters, using the following text as initialization of the network: \n",
    "### There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char=dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_sentence = [char_to_int[char] for char in \"there are those who take mental phenomena naively, just as they would physical phenomena. this school of psychologists tends not to emphasize the object.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of the semses of "
     ]
    }
   ],
   "source": [
    "pattern = seed_sentence[0:100]\n",
    "\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    \n",
    "    prediction=lstm.predict(x, verbose=0)\n",
    "    index=np.argmax(prediction)\n",
    "    result=int_to_char[index]\n",
    "    seq_in=[int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern=pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
